# 開発計画書 (plan.md)

## 1. 開発ロードマップ概要

### Phase 1: GUI Mockup & UX Validation (先行UI開発)
**目標**: 判定ロジックを組み込む前に、デスクトップおよびブラウザ上での「見た目」と「操作感」を確定させる。
**規模**: 約 1単位
**主要タスク**:
- **Desktop Mock**: `eframe/egui` による透過ウィンドウアプリ。ダミー画像/SVGを用いたアバター表示、ホバー時のボタン表示、設定パネルのレイアウト確認。
- **ブラウザ拡張機能版モック (WASM)**: ブラウザサイドパネル内での表示確認。レスポンシブなUI配置の検証。
- **UX検証**: ウィンドウのドラッグ感、ボタンの配置、アバターのサイズ感のフィードバック収集。

### Phase 2: Desktop App MVP & Core Engine (デスクトップ版基盤)
**目標**: 実用的なデスクトップ版の実装と、主要判定ロジックの確立。
**規模**: 約 3〜4単位
**主要機能**:
- **Core Engine**: `ort` (ONNX Runtime) による顔検出と、`RelativePositionStrategy` による判定の実装。
- **Logic Integration**: モックUIに実際のカメラ映像と判定結果を接続。
- **キーボード送信**: `enigo` による物理入力連携。
- **Window Guard**: ターゲットウィンドウ選択機能。

### Phase 3: Browser Extension MVP (ブラウザ拡張機能版への展開)
**目標**: ブラウザ拡張機能としての基本機能実装とAIチャット連携。
**規模**: 約 3単位
**主要機能**:
- **ブラウザ拡張機能版の推論 (WASM)**: `tract-onnx` と Web Worker による非同期判定エンジンの構築。
- **Extension Integration**: サイドパネルUIとコンテンツスクリプト間の通信、タブ操作（文字注入）の実装。

### Phase 4: Voice Synergy & Store Alpha (音声連携と早期公開)
**目標**: 音声機能の追加と、各ストアでの公開準備。
**主要機能**:
- **音声入力/コマンド**: デスクトップ(Vosk)およびブラウザ(Web Speech API / vosk-browser)への対応。

### Phase 5: AI デスクトップ Ecosystem (MCP連携と品質強化)
**主要機能**:
- **MCP対応 (デスクトップ版のみ)**: AIエージェントとの直接通信。
- **高度な演出**: 予告インジケータ、AI背景除去、表情認識の試験導入。

## 2. タスクリスト (直近フェーズ)

### 2.1. Phase 1: GUI Mockup
- [ ] Desktop用モックプロジェクトの作成
- [ ] 透過・枠なしウィンドウの設定検証 (eframe)
- [ ] アバター表示用コンポーネント (AvatarWidget) の実装
- [ ] 設定パネルのプロトタイプ配置
- [ ] ブラウザ拡張機能版用モックプロジェクトの作成 (Trunk)

### 2.2. Phase 2: Desktop MVP
- [ ] `ort` による顔検出モジュールの実装
- [ ] `RelativePositionStrategy` の実装とキャリブレーション調整
- [ ] `enigo` による入力送信の実装

## 3. リスク管理

| リスク | 影響度 | 対策 |
| :--- | :--- | :--- |
| **OSレベルの描画制約 (透過等)** | 中 | `eframe` の設定を早期に検証し、必要に応じてOSネイティブAPIを直接叩く。 |
| **ブラウザのパフォーマンス制約** | 高 | SIMD有効化とWorker分離を前提とし、低解像度での推論を徹底。 |
