# 音声認識・コマンド統合 (voice_integration.md)

ジェスチャー操作を補完し、完全なハンズフリー環境を実現するための音声機能の設計。
Phase 3 での本格実装を見据え、デスクトップ版とブラウザ拡張機能版の両環境における技術選定とUI/UXを定義する。

## 1. コンセプト
- **"Hybrid Interface"**: 「頷き」で確定、「声」でテキスト入力、というように、ジェスチャーと音声をシームレスに組み合わせる。
- **"Privacy First"**: 常時録音は行わず、ユーザーが意図したタイミング（ホットワードやジェスチャーとの組み合わせ）でのみ認識を行う。

## 2. 機能要件

### 2.1. 音声テキスト入力 (Dictation)
- マイクに向かって話した言葉を、そのままテキストとしてアクティブな入力欄に転送する。
- **UX**:
    - 音声入力中はアバターが「聞き耳を立てる」アニメーションに変化。
    - 認識中のテキストをリアルタイムでプレビュー表示（字幕）。

### 2.2. ボイスコマンド (Voice Command)
- 特定のキーワードをトリガーに、アクションを実行する。
- **標準コマンド**:
    - 「送信」「エンター」 → `Enter` キー
    - 「クリア」「消して」 → `Backspace` 連打 or `Ctrl+A` -> `Del`
    - 「キャンセル」 → 入力内容の破棄
- **カスタムエイリアス**:
    - ユーザーが任意の単語（例: 「実行！」「ヨシ！」）をキー操作に割り当て可能。

## 3. 技術スタック

### 3.1. デスクトップ版
- **エンジン**: **`Vosk`** (オフライン音声認識ライブラリ)
    - **理由**:
        - 完全オフライン動作でプライバシーに優れる。
        - 軽量モデル (40MB程度) があり、配布しやすい。
        - 多くの言語（日本語、英語、他）に対応。
- **代替案**: OS標準API (Windows SAPI, macOS NSSpeechRecognizer)
    - 依存関係がOSに縛られるため、クロスプラットフォーム統一のためにVoskを推奨。

### 3.2. ブラウザ拡張機能版
ブラウザ拡張機能版では、ユーザビリティ（初期ロード時間）と機能性（オフライン・プライバシー）のバランスを考慮し、2つのエンジンを検討・併用する。

#### A. **`Web Speech API`** (Primary)
- **概要**: ブラウザ標準の音声認識機能。
- **メリット**: 追加のダウンロードが不要で、ページを開いて即座に利用可能。
- **デメリット**: 多くのブラウザでオンライン接続（クラウド送信）が必要であり、プライバシーやオフライン動作に制約がある。
- **採用方針**: デフォルトのエンジンとして採用。

#### B. **`vosk-browser`** (Secondary / Advanced Option)
- **概要**: VoskのWASMポート。ブラウザ内で完結するオフライン認識を実現する。
- **メリット**:
    - **完全オフライン**: 音声データが外部に送信されない。
    - **AudioWorklet対応**: リアルタイムストリーム処理が可能。
- **課題 (現状の制約)**:
    - **モデルサイズ**: 軽量モデルでも圧縮後で **約40MB〜50MB** あり、初回ロードに時間がかかる。
    - **リソース消費**: WASM上での推論はCPU負荷が高く、モバイル端末等ではバッテリー消費が懸念される。
- **採用方針**: 「設定」でユーザーが明示的に「オフラインモード（高プライバシー）」を選択した場合のみ、モデルをダウンロードして有効化する。

## 4. データフローとアーキテクチャ

```mermaid
graph LR
    Mic[Microphone] --> AudioBuffer
    
    subgraph VoiceEngine [Voice Engine]
        direction TB
        VAD[VAD (Voice Activity Detection)]
        Recognizer[Speech Recognizer (Vosk/WebAPI)]
        CommandParser[Command Parser]
    end
    
    AudioBuffer --> VAD
    VAD -- "Speech Detected" --> Recognizer
    Recognizer -->|Text| CommandParser
    
    CommandParser -- "Command Matched" --> Action[Execute Action (Enigo)]
    CommandParser -- "No Match (Dictation)" --> Type[Type Text (Enigo)]
```

- **VAD (発話区間検出)**: 無音時の無駄な認識処理を省き、CPU負荷を下げる。

## 5. UI/UX

### 5.1. マイク状態の表示
- **UIコンポーネント**: `MicrophoneIndicator`
- **ステータス**:
    - ⚪ **Idle**: 待機中（マイクOFFまたはVAD待機）
    - 🟢 **Listening**: 認識中（波形アニメーション）
    - 🔵 **Processing**: 解析中
    - 🔴 **Error**: マイク未接続または権限なし

### 5.2. フィードバック
- **字幕 (Subtitle)**: 画面下部またはアバター付近に、認識されたテキストを一時表示。
- **コマンド確認**: 「送信」などのコマンドが認識された際、アバターが「了解」のアクション（敬礼など）を行う。
